/** apps/orchestrator-api/src/app/neural-prompt.apparatus.ts */

import { IKnowledgeSemanticChunk } from '@omnisync/core-contracts';

/**
 * @interface INeuralConversationMessage
 * @description Estructura inmutable para la representaciÃ³n de mensajes en el flujo de diÃ¡logo.
 */
interface INeuralConversationMessage {
  readonly role: 'user' | 'assistant' | 'system';
  readonly content: string;
}

/**
 * @name NeuralPromptApparatus
 * @description Aparato de ingenierÃ­a de prompts de alta precisiÃ³n.
 * Orquesta la fusiÃ³n de directivas institucionales, memoria histÃ³rica truncada y
 * fragmentos de conocimiento tÃ©cnico (RAG) para maximizar la exactitud de la inferencia AI.
 *
 * @protocol OEDP-Level: Elite (Cognitive Engineering)
 */
export class NeuralPromptApparatus {
  /**
   * @private
   * @description LÃ­mite de mensajes histÃ³ricos para preservar la ventana de contexto.
   */
  private static readonly MAXIMUM_HISTORY_ENTRIES_RETAINED = 8;

  /**
   * @method buildEnrichedInferencePrompt
   * @description Construye el prompt final inyectando el historial curado y el conocimiento tÃ©cnico.
   *
   * @param {string} systemDirective - InstrucciÃ³n base de comportamiento del Tenant.
   * @param {IKnowledgeSemanticChunk[]} technicalKnowledgeContext - Chunks recuperados de Qdrant.
   * @param {string} userCurrentQuery - Consulta actual del usuario final.
   * @param {unknown[]} conversationHistoryRaw - Historial recuperado de la persistencia volÃ¡til.
   * @returns {string} Prompt estructurado y optimizado para modelos generativos.
   */
  public static buildEnrichedInferencePrompt(
    systemDirective: string,
    technicalKnowledgeContext: IKnowledgeSemanticChunk[],
    userCurrentQuery: string,
    conversationHistoryRaw: unknown[] = []
  ): string {

    const formattedKnowledge = this.formatTechnicalKnowledgeContext(technicalKnowledgeContext);
    const formattedHistory = this.formatConversationHistory(conversationHistoryRaw);

    return `
${systemDirective.trim()}

### ðŸ§  MEMORIA RECIENTE DEL DIÃLOGO (COHERENCIA)
A continuaciÃ³n se presentan los Ãºltimos mensajes para mantener el hilo de la conversaciÃ³n.
${formattedHistory}

### ðŸ“š CONTEXTO TÃ‰CNICO DE REFERENCIA (VERDAD SSOT)
Utiliza la siguiente informaciÃ³n tÃ©cnica recuperada de los manuales oficiales para responder.
${formattedKnowledge}

### ðŸ“¥ CONSULTA ACTUAL DEL USUARIO
${userCurrentQuery.trim()}

---
### ðŸ› ï¸ DIRECTIVAS DE RESPUESTA OBLIGATORIAS:
1. **SoberanÃ­a del Dato**: Si la respuesta no se encuentra en el "CONTEXTO TÃ‰CNICO DE REFERENCIA", informa al usuario que no posees la informaciÃ³n especÃ­fica y sugiere contactar a un experto humano.
2. **Coherencia**: Utiliza la "MEMORIA RECIENTE" para entender pronombres o referencias a mensajes anteriores.
3. **Identidad**: MantÃ©n un tono profesional, resolutivo y arquitectÃ³nico.
4. **RestricciÃ³n**: No menciones tÃ©rminos internos como "Chunks", "Vectores", "Manuales" o "Base de datos" en tu respuesta.
5. **Formato**: Utiliza Markdown para mejorar la legibilidad si es necesario.
`.trim();
  }

  /**
   * @method formatTechnicalKnowledgeContext
   * @private
   */
  private static formatTechnicalKnowledgeContext(chunks: IKnowledgeSemanticChunk[]): string {
    if (chunks.length === 0) {
      return '[AVISO]: No se ha localizado informaciÃ³n tÃ©cnica especÃ­fica en la base de conocimiento.';
    }

    return chunks
      .map((chunk, index) => {
        const sourceIndicator = chunk.sourceName ? `(Fuente: ${chunk.sourceName})` : '';
        return `[RECURSO_TECNICO_${index + 1}] ${sourceIndicator}:\n${chunk.content.trim()}`;
      })
      .join('\n\n');
  }

  /**
   * @method formatConversationHistory
   * @private
   * @description Procesa y trunca el historial para garantizar eficiencia en el consumo de tokens.
   */
  private static formatConversationHistory(history: unknown[]): string {
    if (history.length === 0) {
      return '[INFO]: Iniciando nueva sesiÃ³n de soporte neural.';
    }

    // Truncamiento de seguridad: Solo conservamos los mensajes mÃ¡s recientes.
    const truncatedHistory = history.slice(-this.MAXIMUM_HISTORY_ENTRIES_RETAINED);

    return (truncatedHistory as readonly INeuralConversationMessage[])
      .map((message) => {
        const roleLabel = message.role.toUpperCase();
        return `${roleLabel}: ${message.content.trim()}`;
      })
      .join('\n');
  }
}
